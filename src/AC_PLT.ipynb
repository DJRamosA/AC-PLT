{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPN generator\n",
    "\n",
    "## Table of contents\n",
    "1. [Libraries](##Libraries)\n",
    "2. [Important Variables](##important-variables)\n",
    "3. [Language Setting](#language-setting)\n",
    "4. [Important functions](##important-functions)\n",
    "5. [Data Cleaning](#data-cleaning)\n",
    "6. [Word Embedding](##word-embedding)\n",
    "7. [Model](#model)\n",
    "8. [Codification Suggested](#codification-suggested)\n",
    "\n",
    "## [Libraries](##Libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from collections import Counter \n",
    "import sklearn.cluster\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "\n",
    "# Set of the random seed for the kmeans model\n",
    "random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Important Variables](##important-variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTrainData = r'../your-route/train_data.csv' # Path of the training data\n",
    "pathData = r'../your-route/properties-without-code.csv' # Path of the data to codify\n",
    "numberCluster = 500 # Number of clusters for the k-means model\n",
    "numberCodes = 3 # Number of code you want as suggestion.\n",
    "outputFile = r'../your-route/suggest_codification.csv' # Path for the results of the AC-PLT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Language Setting](#language-setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Cambiar los archivos csv a delimeter=','\n",
    "\n",
    "# Data import\n",
    "# Relative Path of the dataset, change for your dataset\n",
    "data_train = pd.read_csv(pathTrainData, delimiter=\",\")\n",
    "\n",
    "## Import of the data to codify\n",
    "# data_to_code = pd.read_csv(pathData, delimiter=\",\")\n",
    "\n",
    "\n",
    "# Import of the model of the spanish billion words embeddings\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format( \n",
    "    r'../data/SBW-vectors-300-min5.bin.gz', # Relative path of the vector\n",
    "    binary=True # The model is in binary format\n",
    ")\n",
    "\n",
    "# Import of the model of the word2vec-google-news-300 for English dataset\n",
    "# model = gensim.models.KeyedVectors.load_word2vec_format( \n",
    "#     r'../../data/word2vec-google-news-300.model', # Relative path of the vector\n",
    "#     binary=False # The model is in binary format\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used as example, ignore when you use it.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data import\n",
    "data = pd.read_csv(pathTrainData, delimiter=\",\")\n",
    "\n",
    "# Import of the model of the spanish billion words embeddings\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format( \n",
    "    r'../data/SBW-vectors-300-min5.bin.gz', # Relative path of the vector\n",
    "    binary=True # The model is in binary format\n",
    ")\n",
    "\n",
    "pathTrainData=r'../data/CPN120/CPN120.csv'\n",
    "outputFile = r'../data/CPN120/suggest_CPN120.csv'\n",
    "\n",
    "\n",
    "data_train, data_to_code = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concepto</th>\n",
       "      <th>Respuesta</th>\n",
       "      <th>Codigo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granito</td>\n",
       "      <td>tierra</td>\n",
       "      <td>terrestre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>granito</td>\n",
       "      <td>rugoso</td>\n",
       "      <td>texturas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>granito</td>\n",
       "      <td>construcción</td>\n",
       "      <td>material_construccion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>granito</td>\n",
       "      <td>desagradable al tacto</td>\n",
       "      <td>texturas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>granito</td>\n",
       "      <td>raspa</td>\n",
       "      <td>lastimar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Concepto              Respuesta                 Codigo\n",
       "0  granito                 tierra              terrestre\n",
       "1  granito                 rugoso               texturas\n",
       "2  granito           construcción  material_construccion\n",
       "3  granito  desagradable al tacto               texturas\n",
       "4  granito                  raspa               lastimar"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most important is the 3 rows of Concept, Feature and Code.\n",
    "# Code is important for the training of the model.\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation of the Spanish pipeline. Change depending on the language you are using it.\n",
    "\n",
    "More info in the page of spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 245.8 kB/s eta 0:00:52\n",
      "     --------------------------------------- 0.0/12.8 MB 245.8 kB/s eta 0:00:52\n",
      "     --------------------------------------- 0.0/12.8 MB 245.8 kB/s eta 0:00:52\n",
      "     --------------------------------------- 0.1/12.8 MB 385.0 kB/s eta 0:00:33\n",
      "     --------------------------------------- 0.1/12.8 MB 385.0 kB/s eta 0:00:33\n",
      "     --------------------------------------- 0.1/12.8 MB 312.9 kB/s eta 0:00:41\n",
      "      -------------------------------------- 0.2/12.8 MB 452.9 kB/s eta 0:00:28\n",
      "      -------------------------------------- 0.2/12.8 MB 509.6 kB/s eta 0:00:25\n",
      "      -------------------------------------- 0.2/12.8 MB 509.6 kB/s eta 0:00:25\n",
      "     - ------------------------------------- 0.3/12.8 MB 599.0 kB/s eta 0:00:21\n",
      "     - ------------------------------------- 0.4/12.8 MB 636.6 kB/s eta 0:00:20\n",
      "     - ------------------------------------- 0.5/12.8 MB 734.9 kB/s eta 0:00:17\n",
      "     - ------------------------------------- 0.5/12.8 MB 779.3 kB/s eta 0:00:16\n",
      "     - ------------------------------------- 0.5/12.8 MB 779.3 kB/s eta 0:00:16\n",
      "     - ------------------------------------- 0.5/12.8 MB 779.3 kB/s eta 0:00:16\n",
      "     - ------------------------------------- 0.6/12.8 MB 742.0 kB/s eta 0:00:17\n",
      "     - ------------------------------------- 0.6/12.8 MB 742.0 kB/s eta 0:00:17\n",
      "     -- ------------------------------------ 0.7/12.8 MB 744.1 kB/s eta 0:00:17\n",
      "     -- ------------------------------------ 0.7/12.8 MB 739.7 kB/s eta 0:00:17\n",
      "     -- ------------------------------------ 0.8/12.8 MB 755.9 kB/s eta 0:00:16\n",
      "     -- ------------------------------------ 0.9/12.8 MB 799.5 kB/s eta 0:00:15\n",
      "     -- ------------------------------------ 0.9/12.8 MB 809.2 kB/s eta 0:00:15\n",
      "     -- ------------------------------------ 0.9/12.8 MB 809.2 kB/s eta 0:00:15\n",
      "     -- ------------------------------------ 0.9/12.8 MB 740.5 kB/s eta 0:00:17\n",
      "     --- ----------------------------------- 1.0/12.8 MB 811.0 kB/s eta 0:00:15\n",
      "     --- ----------------------------------- 1.1/12.8 MB 860.6 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.2/12.8 MB 886.7 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.2/12.8 MB 880.9 kB/s eta 0:00:14\n",
      "     --- ----------------------------------- 1.3/12.8 MB 875.9 kB/s eta 0:00:14\n",
      "     ---- ---------------------------------- 1.4/12.8 MB 903.3 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.4/12.8 MB 918.6 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.5/12.8 MB 915.0 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.5/12.8 MB 926.3 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 930.9 kB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 944.0 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 944.0 kB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 892.4 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.7/12.8 MB 916.3 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.7/12.8 MB 909.7 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.7/12.8 MB 909.7 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.8/12.8 MB 870.4 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.8/12.8 MB 876.9 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.9/12.8 MB 896.9 kB/s eta 0:00:13\n",
      "     ----- --------------------------------- 1.9/12.8 MB 910.8 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.0/12.8 MB 914.6 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.1/12.8 MB 916.3 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.1/12.8 MB 926.4 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.1/12.8 MB 918.3 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.1/12.8 MB 918.3 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.2/12.8 MB 893.4 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.2/12.8 MB 893.3 kB/s eta 0:00:12\n",
      "     ------ -------------------------------- 2.3/12.8 MB 897.0 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.3/12.8 MB 900.6 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.4/12.8 MB 910.2 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.5/12.8 MB 930.6 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.5/12.8 MB 933.3 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.6/12.8 MB 936.0 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.7/12.8 MB 944.6 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.7/12.8 MB 948.7 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.7/12.8 MB 951.0 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 951.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 951.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 951.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 951.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 951.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 951.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 951.1 kB/s eta 0:00:11\n",
      "     -------- ------------------------------ 2.8/12.8 MB 863.3 kB/s eta 0:00:12\n",
      "     -------- ------------------------------ 2.8/12.8 MB 864.3 kB/s eta 0:00:12\n",
      "     -------- ------------------------------ 2.9/12.8 MB 863.5 kB/s eta 0:00:12\n",
      "     -------- ------------------------------ 2.9/12.8 MB 863.5 kB/s eta 0:00:12\n",
      "     -------- ------------------------------ 2.9/12.8 MB 848.9 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.0/12.8 MB 850.1 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.0/12.8 MB 853.3 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.1/12.8 MB 859.3 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.1/12.8 MB 850.3 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.1/12.8 MB 851.2 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.1/12.8 MB 849.6 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.1/12.8 MB 849.6 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.2/12.8 MB 832.5 kB/s eta 0:00:12\n",
      "     --------- ----------------------------- 3.3/12.8 MB 843.6 kB/s eta 0:00:12\n",
      "     ---------- ---------------------------- 3.3/12.8 MB 851.8 kB/s eta 0:00:12\n",
      "     ---------- ---------------------------- 3.4/12.8 MB 865.2 kB/s eta 0:00:11\n",
      "     ---------- ---------------------------- 3.5/12.8 MB 875.5 kB/s eta 0:00:11\n",
      "     ---------- ---------------------------- 3.6/12.8 MB 885.6 kB/s eta 0:00:11\n",
      "     ----------- --------------------------- 3.6/12.8 MB 891.4 kB/s eta 0:00:11\n",
      "     ----------- --------------------------- 3.7/12.8 MB 898.6 kB/s eta 0:00:11\n",
      "     ----------- --------------------------- 3.8/12.8 MB 904.7 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.9/12.8 MB 909.1 kB/s eta 0:00:10\n",
      "     ----------- --------------------------- 3.9/12.8 MB 913.5 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.0/12.8 MB 915.6 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.1/12.8 MB 924.5 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.1/12.8 MB 934.1 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.2/12.8 MB 930.3 kB/s eta 0:00:10\n",
      "     ------------ -------------------------- 4.2/12.8 MB 936.5 kB/s eta 0:00:10\n",
      "     ------------- ------------------------- 4.3/12.8 MB 943.6 kB/s eta 0:00:10\n",
      "     ------------- ------------------------- 4.4/12.8 MB 949.6 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.4/12.8 MB 949.9 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.5/12.8 MB 953.4 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.5/12.8 MB 953.4 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.5/12.8 MB 953.4 kB/s eta 0:00:09\n",
      "     ------------- ------------------------- 4.5/12.8 MB 937.5 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.6/12.8 MB 942.1 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.6/12.8 MB 939.4 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.8/12.8 MB 953.1 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.8/12.8 MB 959.5 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.9/12.8 MB 964.7 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.9/12.8 MB 960.9 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.9/12.8 MB 960.9 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.9/12.8 MB 960.9 kB/s eta 0:00:09\n",
      "     -------------- ------------------------ 4.9/12.8 MB 960.9 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 4.9/12.8 MB 927.9 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.0/12.8 MB 928.3 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.0/12.8 MB 923.1 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.1/12.8 MB 934.0 kB/s eta 0:00:09\n",
      "     --------------- ----------------------- 5.2/12.8 MB 944.7 kB/s eta 0:00:09\n",
      "     ---------------- ---------------------- 5.3/12.8 MB 957.0 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.4/12.8 MB 960.1 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 972.1 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 976.6 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 976.6 kB/s eta 0:00:08\n",
      "     ---------------- ---------------------- 5.5/12.8 MB 976.6 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.6/12.8 MB 961.8 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.7/12.8 MB 978.6 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.9/12.8 MB 989.8 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 5.9/12.8 MB 996.0 kB/s eta 0:00:07\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 6.1/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 6.2/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     ------------------- -------------------- 6.3/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 6.5/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 6.5/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.0 MB/s eta 0:00:07\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.7/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.7/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.8/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.9/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 7.0/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.2/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ----------------------- ---------------- 7.7/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 7.7/12.8 MB 1.0 MB/s eta 0:00:06\n",
      "     ------------------------ --------------- 7.8/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.8/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.8/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.8/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 8.0/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 8.0/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 8.2/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 8.2/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     ------------------------- -------------- 8.3/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.3/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.4/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.5/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.6/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     -------------------------- ------------- 8.6/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.0 MB/s eta 0:00:05\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.8/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.8/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.0/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 9.6/12.8 MB 1.0 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.8/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.8/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.8/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.9/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.1/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.3/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.3/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.3/12.8 MB 1.0 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.4/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.4/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 10.5/12.8 MB 1.1 MB/s eta 0:00:03\n",
      "     --------------------------------- ------ 10.7/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.7/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.8/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 10.9/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.5/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.1 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 1.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.24.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dra98\\onedrive\\documentos\\trabajo\\tesis\\codigo\\generadorcpn\\venv\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Download each one depending on your language preference\n",
    "\n",
    "## English\n",
    "# !python -m spacy download en_core_news_sm\n",
    "\n",
    "## Spanish\n",
    "# !python -m spacy download es_core_news_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of spacy for Spanish\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "\n",
    "# Configuration of spacy for English\n",
    "# nlp = spacy.load('en_core_news_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Important functions](##important-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Recive a string and return the string in tokens without punctuations\n",
    "    and in lowercase\n",
    "    \"\"\"\n",
    "    # for each token in the sentence add to the list if is not a punctuation\n",
    "    return [t for t in nlp(text.lower()) if not t.is_punct]\n",
    "\n",
    "\n",
    "def normalize(tokens):\n",
    "    \"\"\"\n",
    "    Recive al list of string and return in one string without stop words\n",
    "    \"\"\"\n",
    "    # for each token if is not a stop word add the word to the list\n",
    "    words = [t.orth_ for t in tokens if not t.is_stop]\n",
    "\n",
    "    # return the tokens in one string\n",
    "    return(\" \".join(words))\n",
    "\n",
    "# Just in case you want to use it replace for normalize\n",
    "def lematize(tokens):\n",
    "    \"\"\"\n",
    "    Recive al list of string and return in one string without stop words \n",
    "    and Lematized\n",
    "    \"\"\"\n",
    "    # for each token if is not a stop word add the lemma of the word in the list\n",
    "    lemmas = [t.lemma_ for t in tokens if not t.is_stop]\n",
    "\n",
    "    # return the tokens in one string\n",
    "    return(\" \".join(lemmas))\n",
    "\n",
    "\n",
    "def to_vector(texto, model):\n",
    "    \"\"\" \n",
    "    Receives a sentence string along with a word embedding model and \n",
    "    returns the vector representation of the sentence\n",
    "    \"\"\"\n",
    "    tokens = texto.split() # splits the text by space and returns a list of words\n",
    "    vec = np.zeros(300) # creates an empty vector of 300 dimensions\n",
    "    for word in tokens: # iterates over the sentence\n",
    "        if word in model: # checks if the word is both in the word embedding\n",
    "            vec += model[word] # adds every word embedding to the vector\n",
    "    return vec / np.linalg.norm(vec) if np.linalg.norm(vec)>0 else vec # divides the vector by their normal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Data Cleaning](##data-cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceution time: 102.67801928520203\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Normalize of the feature\n",
    "for i in range(len(data_train)):\n",
    "    data_train.iloc[i,1] = normalize(clean_text(data_train.iloc[i,1])) # Change for the name of your dataset\n",
    "\n",
    "for i in range(len(data_to_code)):\n",
    "    data_to_code.iloc[i,1] = normalize(clean_text(data_to_code.iloc[i,1])) # Change for the name of your dataset\n",
    "end = time.time()\n",
    "print(\"Exceution time:\", end-start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Word Embedding](##word-embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceution time: 1.8939287662506104\n"
     ]
    }
   ],
   "source": [
    "# Timer\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Creation of the matrix to make the clustering process\n",
    "descriptions_matrix = np.zeros( # creatign an empty matrix\n",
    "    (\n",
    "        len(data_train), # the number of data points\n",
    "        len(model['hola']) # the number of components of the word embedding\n",
    "    )\n",
    ")\n",
    "\n",
    "# Matrix filling \n",
    "# Change to the name of the descriptions of your dataset.\n",
    "for i,description in enumerate(data_train.iloc[:,1]):\n",
    "    vector = to_vector(description,model)\n",
    "    descriptions_matrix[i,] = vector\n",
    "\n",
    "# Concatenate the matrix with the data of each observation\n",
    "data_matrix = np.concatenate([descriptions_matrix,data_train], axis=1)\n",
    "\n",
    "\n",
    "# Remove of the 'Nan' data\n",
    "data_matrix = data_matrix[~pd.isnull(data_matrix[:,:300]).any(axis=1)]\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"Exceution time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceution time: 0.5245153903961182\n"
     ]
    }
   ],
   "source": [
    "# Timer\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Creation of the matrix to make the clustering process\n",
    "descriptions_matrix = np.zeros( # creatign an empty matrix\n",
    "    (\n",
    "        len(data_to_code), # the number of data points\n",
    "        len(model['hola']) # the number of components of the word embedding\n",
    "    )\n",
    ")\n",
    "\n",
    "# Matrix filling \n",
    "# Change to the name of the descriptions of your dataset.\n",
    "for i,description in enumerate(data_to_code.iloc[:,1]):\n",
    "    vector = to_vector(description,model)\n",
    "    descriptions_matrix[i,] = vector\n",
    "\n",
    "# Concatenate the matrix with the data of each observation\n",
    "matrix_to_code = np.concatenate([descriptions_matrix,data_to_code], axis=1)\n",
    "\n",
    "\n",
    "# Remove of the 'Nan' data\n",
    "matrix_to_code = matrix_to_code[~pd.isnull(matrix_to_code[:,:300]).any(axis=1)]\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"Exceution time:\", end-start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Model](#model)\n",
    "\n",
    "We create a class for the text classification, were initially you have to set the number of clusters you want to use for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AC_PLT:\n",
    "\n",
    "    def __init__(self, n_clusters = 500, random_state=0):\n",
    "        \"\"\"\n",
    "        n_clusters: number of cluster in the k-Means model\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n_clusters = n_clusters # number of clusters\n",
    "        self.KMeans_dict = {} # dictionary of all the humans codifications for each Cluster\n",
    "        self.KMeans_categories = {} # dictionary for the most frecuent value in the centroid\n",
    "        self.km = sklearn.cluster.KMeans(           # creates de k-means object\n",
    "            n_clusters=self.n_clusters, \n",
    "            random_state=random_state,\n",
    "            n_init='auto'\n",
    "        ) \n",
    "        \n",
    "        \n",
    "    def most_frequent(self, List): \n",
    "        \"\"\"\n",
    "        Recives a list of words, and return the word most frequente of\n",
    "        the list\n",
    "        \"\"\"\n",
    "        # counter of occurence of a code in a list\n",
    "        occurence_count = Counter(List) \n",
    "        \n",
    "        # Return the first code with more occurence\n",
    "        return occurence_count.most_common(1)[0][0] \n",
    "\n",
    "\n",
    "    def fit(self, train):\n",
    "        \"\"\"\n",
    "        Recives the train dataset and the number of clusters to train \n",
    "        the k-means model\n",
    "        \"\"\"\n",
    "        # Train the k-means algorithm\n",
    "        self.km.fit(train[:,:300])\n",
    "\n",
    "        # Dataframe of train dataset\n",
    "        df = pd.DataFrame(\n",
    "            np.concatenate([\n",
    "                np.reshape(train[:,302], (-1, 1)),          # Human codification\n",
    "                np.reshape(self.km.labels_, (-1, 1)),       # Number of the KMean centroid\n",
    "                np.reshape(train[:,300], (-1, 1))           # Concept of the codification\n",
    "                ], axis=1), \n",
    "            columns=['Human', 'KMeans', 'Concept'])\n",
    "\n",
    "        # create a dictionary of all the humans codifications for each Cluster\n",
    "        self.KMeans_dict = df.groupby(by='KMeans')['Human'].apply(list).to_dict()\n",
    "\n",
    "        # Fill a dictionary with the most frecuent value in the centroid\n",
    "        for key, val in self.KMeans_dict.items():\n",
    "            self.KMeans_categories[key] = self.most_frequent(val)\n",
    "        \n",
    "        # Generates the prediction for the train dataset\n",
    "        df['KM_Prediction'] = df['KMeans'].map(self.KMeans_categories)\n",
    "\n",
    "\n",
    "    def get_distances(self, test):\n",
    "        \"\"\"\n",
    "        recives the test data to calculate the distances of each frase, return \n",
    "        a matrix with the distances sorted\n",
    "        \"\"\"\n",
    "        \n",
    "        # Distance matrix of each test point to each cluster center\n",
    "        distance_matrix = distance.cdist(test[:,:300].astype(float), self.km.cluster_centers_, 'euclidean')\n",
    "        \n",
    "        # Sorting distances\n",
    "        self.topk=np.argsort(distance_matrix,axis=1)\n",
    "        \n",
    "    \n",
    "    def set_labels(self):\n",
    "        \"\"\"\n",
    "        Create a new matrix from the clusters sorted and change the value\n",
    "        from numeric to the string according the codification\n",
    "        \"\"\"\n",
    "        # Change of the numeric value to the codification \n",
    "        self.topKS=pd.DataFrame(self.topk)\n",
    "\n",
    "        # create a temporal array of the kmeans categories\n",
    "        tempData = np.array([value for (_, value) in sorted(self.KMeans_categories.items())])\n",
    "        \n",
    "        # print(tempData)\n",
    "\n",
    "        # for each cluster center\n",
    "        for j in range(self.topKS.shape[1]):\n",
    "            # set the codification of the numeric value in the topk list\n",
    "            self.topKS.iloc[:,j]=tempData[self.topk[:,j]]\n",
    "\n",
    "\n",
    "    def get_accuracies(self, test):\n",
    "        \"\"\"\n",
    "        Recives the test matrix and return the accuracies of the \n",
    "        diferents predictions\n",
    "        \"\"\"\n",
    "        #Creating the accuracy table to check each data point\n",
    "        testLabel=np.zeros(self.topKS.shape)\n",
    "        indexes_method0=pd.DataFrame(np.zeros((self.topKS.shape[0],2)), columns=['index', 'value']) \n",
    "\n",
    "        #For each data point\n",
    "        for i in range(testLabel.shape[0]):\n",
    "            #Checking if some of the cluster is able to classify it right\n",
    "            boolClass=self.topKS.iloc[i,:]==test[i,302]\n",
    "            if sum(boolClass)>0:\n",
    "                getIndex=boolClass.idxmax()\n",
    "                indexes_method0.iloc[i,0] = getIndex\n",
    "                indexes_method0.iloc[i,1] = self.topKS.iloc[i,getIndex]\n",
    "                #Setting the rest of the data point as 1\n",
    "                testLabel[i,getIndex:]=1\n",
    "            else:\n",
    "                indexes_method0.iloc[i,0] = np.nan\n",
    "                indexes_method0.iloc[i,1] = np.nan\n",
    "        accuracies=testLabel.sum(axis=0)/testLabel.shape[0]\n",
    "\n",
    "        return accuracies\n",
    "\n",
    "    \n",
    "    def transform(self, test):\n",
    "        \"\"\"\n",
    "        Recives two numpy bi-dimentionals arrays and returns the accuracy of the model\n",
    "        \"\"\"\n",
    "        self.get_distances(test)\n",
    "        self.set_labels()\n",
    "        return self.get_accuracies(test)\n",
    "    \n",
    "    def suggestions(self, test, n_codes):\n",
    "        self.get_distances(test)\n",
    "        self.set_labels()\n",
    "        return pd.DataFrame(\n",
    "            np.concatenate([\n",
    "                np.reshape(test[:, 300], (-1, 1)), \n",
    "                np.reshape(test[:, 301], (-1, 1)), \n",
    "                self.topKS.iloc[:, :n_codes]],\n",
    "                axis=1\n",
    "                ), \n",
    "            columns=['Concept', 'Description']+['top-{} suggestion'.format(i+1) for i in range(numberCodes)]\n",
    "            )\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Codification Suggested](#codification-suggested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train process time: 5.755473375320435\n",
      "Clasification process time: 3.127873420715332\n"
     ]
    }
   ],
   "source": [
    "# Instance of the model\n",
    "proc = AC_PLT(n_clusters=numberCluster)\n",
    "\n",
    "# Train process\n",
    "start = time.time()\n",
    "proc.fit(data_matrix)\n",
    "end = time.time()\n",
    "print(\"Train process time:\", end-start)\n",
    "\n",
    "# creation of Dataframe with the suggested codes\n",
    "start = time.time()\n",
    "df = proc.suggestions(matrix_to_code, n_codes=numberCodes)\n",
    "end = time.time()\n",
    "print(\"Clasification process time:\", end-start)\n",
    "\n",
    "# Saving the dataframe into a csv file\n",
    "df.to_csv(outputFile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "39d3428004f928037450bcaf2ccddacfbb5d68c6243c2762d0ea346348cf1412"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
