{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from collections import Counter \n",
    "import sklearn.cluster\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "data = pd.read_excel(r'../data/Datos Codificados Estudio v2a.xlsx')\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format( \n",
    "    r'../Data/SBW-vectors-300-min5.bin.gz', # using the spanish billion words embeddings\n",
    "    binary=True # the model is in binary format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[[\"Palabra (concepto)\", \"Descripción\", \"Codificación\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Recive a string and return the string in tokens without punctuations\n",
    "    and in lowercase\n",
    "    \"\"\"\n",
    "    # for each token in the sentence add to the list if is not a punctuation\n",
    "    return [t for t in nlp(text.lower()) if not t.is_punct]\n",
    "    \n",
    "def normalize(tokens):\n",
    "    \"\"\"\n",
    "    Recive al list of string and return in one string without stop words\n",
    "    \"\"\"\n",
    "    # for each token if is not a stop word add the word to the list\n",
    "    words = [t.orth_ for t in tokens if not t.is_stop]\n",
    "\n",
    "    # return the tokens in one string\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion de los conceptos, descripciones y codificaciones\n",
    "for i in range(len(data)):\n",
    "    df['Descripción'][i] = normalize(clean_text(df['Descripción'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         sentimiento\n",
       "1    perdona vida a alguien peliculas\n",
       "2         necesario cumplir objetivos\n",
       "3       organizar recursos o personas\n",
       "4                          estrategia\n",
       "Name: Descripción, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Descripción'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: LSA \n",
    "# ? La impletemtación es a todo el dataset o solo a las palabras del train dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "contador = CountVectorizer()\n",
    "tf = contador.fit_transform(df['Descripción'])\n",
    "transf = TfidfTransformer()\n",
    "tfidf = transf.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3323 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[0]\n",
    "# contador.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 1296 # es el numero de codificaciones existentes\n",
    "# numDim = 33 # numero de conceptos\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(lsa.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4938, 1296)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# el vector de los terminos es el resultado del fit_transform\n",
    "tfidf_lsa_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,df[[\"Palabra (concepto)\", \"Codificación\", \"Descripción\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class creation\n",
    "class PLT_processor:\n",
    "\n",
    "    def __init__(self, method = 0, n_clusters = 500, vect_size = 300):\n",
    "        \"\"\"\n",
    "        Recives the type of method to use, \n",
    "        - 0: Clasify using K-Means (Simple)\n",
    "        - 1: Clasify to the codification with the same concept \n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.method = method # Method of Processing the data\n",
    "        self.vect_size = vect_size\n",
    "        self.KMeans_dict = {}\n",
    "        self.KMeans_categories = {}\n",
    "\n",
    "        if method == 1:\n",
    "            self.inverse_concept_cluster = {}\n",
    "            self.concept_cluster = {}\n",
    "\n",
    "\n",
    "    def most_frequent(self, List): \n",
    "        \"\"\"\n",
    "        Recives a list of words, and return the word most frequente of\n",
    "        the list\n",
    "        \"\"\"\n",
    "        # ? Agregar la frase 'PENDIENTE' en caso de que haya multiples codificaciones con la misma frecuencia ?\n",
    "        occurence_count = Counter(List) \n",
    "        return occurence_count.most_common(1)[0][0] \n",
    "\n",
    "\n",
    "    def model_train(self, train):\n",
    "        \"\"\"\n",
    "        Recives the train dataset and the number of clusters to train \n",
    "        the k-means model\n",
    "        \"\"\"\n",
    "        \n",
    "        # If the number of clusters is less than the data points aply K Means\n",
    "        if(len(train)>self.n_clusters):\n",
    "            # creates de k-means object\n",
    "            self.kemean = sklearn.cluster.KMeans(n_clusters=self.n_clusters, random_state=0)\n",
    "            # Train the k-means algorithm\n",
    "            self.kemean.fit(train[:,:self.vect_size])\n",
    "\n",
    "            # print(self.kemean.n_clusters)\n",
    "            # Dataframe of train dataset\n",
    "            df = pd.DataFrame(\n",
    "                np.concatenate([\n",
    "                    np.reshape(train[:,self.vect_size+1], (-1, 1)),          # Human codification\n",
    "                    np.reshape(self.kemean.labels_, (-1, 1)),   # Number of the KMean centroid\n",
    "                    np.reshape(train[:,self.vect_size], (-1, 1))           # Concept of the codification\n",
    "                    ], axis=1), \n",
    "                columns=['Human', 'KMeans', 'Concept'])\n",
    "        # Else if the number of clusters is equal than the data points set a number to each point\n",
    "        elif(len(train)==self.n_clusters):\n",
    "             # Dataframe of train dataset\n",
    "            df = pd.DataFrame(\n",
    "                np.concatenate([\n",
    "                    np.reshape(train[:,self.vect_size+1], (-1, 1)),          # Human codification\n",
    "                    np.reshape(range(self.n_clusters), (-1, 1)),   # Number of the KMean centroid\n",
    "                    np.reshape(train[:,self.vect_size], (-1, 1))           # Concept of the codification\n",
    "                    ], axis=1), \n",
    "                columns=['Human', 'KMeans', 'Concept'])\n",
    "\n",
    "            self.cluster_centers_2 = train[:,:self.vect_size].astype(float)\n",
    "\n",
    "        # create a dictionary of all the humans codifications for each Cluster\n",
    "        self.KMeans_dict = df.groupby(by='KMeans')['Human'].apply(list).to_dict()\n",
    "\n",
    "        # Fill a dictionary with the most frecuent value in the centroid\n",
    "        for key, val in self.KMeans_dict.items():\n",
    "            self.KMeans_categories[key] = self.most_frequent(val)\n",
    "        \n",
    "        # Generates the prediction for the train dataset\n",
    "        df['KM_Prediction'] = df['KMeans'].map(self.KMeans_categories)\n",
    "\n",
    "        if self.method == 1:\n",
    "            # dictionary of the codifications that doesn't show in a concept\n",
    "            self.not_concept_cluster = {\n",
    "                i:[False if j in np.unique(df['KMeans'][df['Concept']==i]) else True for j in range(self.n_clusters)] \n",
    "                for i in np.unique(df['Concept'])\n",
    "                }\n",
    "            # dictionary of clusters for each concept\n",
    "            self.concept_cluster = {\n",
    "                i:np.unique(df['KMeans'][df['Concept']==i]) for i in np.unique(df['Concept'])\n",
    "                }\n",
    "        # return self.kemean.inertia_\n",
    "\n",
    "    \n",
    "    def get_distances(self, test):\n",
    "        \"\"\"\n",
    "        recives the test data to calculate the distances of each frase, return \n",
    "        a matrix with the distances sorted\n",
    "        \"\"\"\n",
    "\n",
    "        # Distance matrix of each test point to each cluster center\n",
    "        distance_matrix = np.zeros((test.shape[0],self.n_clusters))\n",
    "\n",
    "        if(len(train)>self.n_clusters):\n",
    "            # for each cluster center\n",
    "            for i in range(distance_matrix.shape[1]):    \n",
    "                # Euclidian distance of each point to the i-est cluster center\n",
    "                distance_matrix[:,i]=np.sqrt(np.sum((test[:,:self.vect_size].astype(float)-self.kemean.cluster_centers_[i,:])**2,axis=1))\n",
    "        elif(len(train)==self.n_clusters):\n",
    "            for i in range(distance_matrix.shape[1]):    \n",
    "                # Euclidian distance of each point to the i-est cluster center\n",
    "                distance_matrix[:,i]=np.sqrt(np.sum((test[:,:self.vect_size].astype(float)-self.cluster_centers_2[i,:])**2,axis=1))\n",
    "        \n",
    "\n",
    "        if self.method == 1:\n",
    "            # for each datapoint\n",
    "            for i in range(distance_matrix.shape[0]):\n",
    "                # if the centroid not share the same concept asing NaN value\n",
    "                distance_matrix[i, self.not_concept_cluster[test[i,self.vect_size]]] = np.nan\n",
    "    \n",
    "\n",
    "        # Sorting distances\n",
    "        self.topk=np.argsort(distance_matrix,axis=1)\n",
    "\n",
    "    \n",
    "    def set_labels(self, test):\n",
    "        \"\"\"\n",
    "        Create a new matrix from the clusters sorted and change the value\n",
    "        from numeric to the string according the codification\n",
    "        \"\"\"\n",
    "\n",
    "        # Change of the numeric value to the codification \n",
    "        self.topKS=pd.DataFrame(self.topk)\n",
    "\n",
    "        # create a temporal array of the kmeans categories\n",
    "        tempData = np.array([value for (_, value) in sorted(self.KMeans_categories.items())])\n",
    "        \n",
    "        # for each cluster center\n",
    "        # print(\"Setting labels\")\n",
    "        # print('len temp',len(self.KMeans_categories))\n",
    "        # print('dim topKS',self.topKS.shape[1])\n",
    "        for j in range(self.topKS.shape[1]):\n",
    "            # set the codification of the numeric value in the topk list\n",
    "            self.topKS.iloc[:,j]=tempData[self.topk[:,j]]\n",
    "        \n",
    "        if self.method == 1:\n",
    "            # for each datapoint\n",
    "            for i in range(self.topKS.shape[0]):\n",
    "                # Remove of the clusters that not share the same concept\n",
    "                self.topKS.iloc[i, np.isin(self.topk[i,:], self.concept_cluster[test[i,self.vect_size]] ,invert=True)]= np.nan\n",
    "\n",
    "\n",
    "    def get_accuracies(self, test):\n",
    "        \"\"\"\n",
    "        Recives the test matrix and return the accuracies of the \n",
    "        diferents predictions\n",
    "        \"\"\"\n",
    "        #Creating the accuracy table to check each data point\n",
    "        testLabel=np.zeros(self.topKS.shape)\n",
    "        indexes_method0=pd.DataFrame(np.zeros((self.topKS.shape[0],2)), columns=['index', 'value']) \n",
    "\n",
    "        #For each data point\n",
    "        for i in range(testLabel.shape[0]):\n",
    "            #Checking if some of the cluster is able to classify it right\n",
    "            boolClass=self.topKS.iloc[i,:]==test[i,numDim+1]\n",
    "            if sum(boolClass)>0:\n",
    "                getIndex=boolClass.idxmax()\n",
    "                indexes_method0.iloc[i,0] = getIndex\n",
    "                indexes_method0.iloc[i,1] = self.topKS.iloc[i,getIndex]\n",
    "                #Setting the rest of the data point as 1\n",
    "                testLabel[i,getIndex:]=1\n",
    "            else:\n",
    "                indexes_method0.iloc[i,0] = np.nan\n",
    "                indexes_method0.iloc[i,1] = np.nan\n",
    "        accuracies=testLabel.sum(axis=0)/testLabel.shape[0]\n",
    "\n",
    "        return accuracies\n",
    "\n",
    "    def process(self, train, test):\n",
    "        self.model_train(train)\n",
    "        self.get_distances(test)\n",
    "        self.set_labels(test)\n",
    "        return self.get_accuracies(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k500_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k500_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36917991 0.41657048 0.42365878 0.43094971 0.46598288]\n",
      "[0.02037525 0.02654453 0.02815781 0.02929517 0.02300917]\n"
     ]
    }
   ],
   "source": [
    "print(k500_acc_top.mean(axis=0))\n",
    "print(k500_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 300 # igual al word2vec\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)\n",
    "\n",
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,df[[\"Palabra (concepto)\", \"Codificación\", \"Descripción\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n",
    "\n",
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "lsa300_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        lsa300_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37221675 0.42527493 0.43560251 0.4441074  0.48298877]\n",
      "[0.01519746 0.02099153 0.02197139 0.02296627 0.02383883]\n"
     ]
    }
   ],
   "source": [
    "print(lsa300_acc_top.mean(axis=0))\n",
    "print(lsa300_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 26 # numero de conceptos\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)\n",
    "\n",
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,df[[\"Palabra (concepto)\", \"Codificación\", \"Descripción\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n",
    "\n",
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "lsa33_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        lsa33_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2008975  0.22722293 0.23613248 0.25131938 0.32037582]\n",
      "[0.02328485 0.02300543 0.02411871 0.02274286 0.02964141]\n"
     ]
    }
   ],
   "source": [
    "print(lsa33_acc_top.mean(axis=0))\n",
    "print(lsa33_acc_top.std(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f86d5b59def65e88dbeda6389e0ae43ef80c1809fa447fa67ec7c4f0e393c674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
