{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPN generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from collections import Counter \n",
    "import sklearn.cluster\n",
    "import random\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "data = pd.read_csv(r'../../data/nueva_data/propiedades_codigo.csv', delimiter=\"\\t\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format( \n",
    "    r'../../data/SBW-vectors-300-min5.bin', # using the spanish billion words embeddings\n",
    "    binary=True # the model is in binary format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concepto</th>\n",
       "      <th>Respuesta</th>\n",
       "      <th>Codigo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granito</td>\n",
       "      <td>tierra</td>\n",
       "      <td>terrestre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>granito</td>\n",
       "      <td>rugoso</td>\n",
       "      <td>texturas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>granito</td>\n",
       "      <td>construcción</td>\n",
       "      <td>material_construccion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>granito</td>\n",
       "      <td>desagradable al tacto</td>\n",
       "      <td>texturas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>granito</td>\n",
       "      <td>raspa</td>\n",
       "      <td>lastimar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Concepto              Respuesta                 Codigo\n",
       "0  granito                 tierra              terrestre\n",
       "1  granito                 rugoso               texturas\n",
       "2  granito           construcción  material_construccion\n",
       "3  granito  desagradable al tacto               texturas\n",
       "4  granito                  raspa               lastimar"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuracion de spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "# nlp.Defaults.stop_words.add(\"my_new_stopword\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Recive a string and return the string in tokens without punctuations\n",
    "    and in lowercase\n",
    "    \"\"\"\n",
    "    # for each token in the sentence add to the list if is not a punctuation\n",
    "    return [t for t in nlp(text.lower()) if not t.is_punct]\n",
    "\n",
    "\n",
    "def normalize(tokens):\n",
    "    \"\"\"\n",
    "    Recive al list of string and return in one string without stop words\n",
    "    \"\"\"\n",
    "    # for each token if is not a stop word add the word to the list\n",
    "    words = [t.orth_ for t in tokens if not t.is_stop]\n",
    "\n",
    "    # return the tokens in one string\n",
    "    return(\" \".join(words))\n",
    "\n",
    "\n",
    "def lematize(tokens):\n",
    "    \"\"\"\n",
    "    Recive al list of string and return in one string without stop words \n",
    "    and Lematized\n",
    "    \"\"\"\n",
    "    # for each token if is not a stop word add the lemma of the word in the list\n",
    "    lemmas = [t.lemma_ for t in tokens if not t.is_stop]\n",
    "\n",
    "    # return the tokens in one string\n",
    "    return(\" \".join(lemmas))\n",
    "\n",
    "def to_vector(texto,model):\n",
    "    \"\"\" \n",
    "    Receives a sentence string along with a word embedding model and \n",
    "    returns the vector representation of the sentence\n",
    "    \"\"\"\n",
    "    tokens = texto.split() # splits the text by space and returns a list of words\n",
    "    vec = np.zeros(300) # creates an empty vector of 300 dimensions\n",
    "    for word in tokens: # iterates over the sentence\n",
    "        if word in model: # checks if the word is both in the word embedding\n",
    "            vec += model[word] # adds every word embedding to the vector\n",
    "    return vec / np.linalg.norm(vec) # divides the vector by their normal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None # Para evitar que se muestre warnings\n",
    "\n",
    "# Normalizacion de los conceptos, descripciones y codificaciones\n",
    "for i in range(len(data)):\n",
    "    data['Respuesta'][i] = normalize(clean_text(data['Respuesta'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de Matriz de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-89365e79bd8b>:42: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Creation of the matrix to make the clustering process\n",
    "descriptions_matrix = np.zeros( # creatign an empty matrix\n",
    "    (\n",
    "        len(data), # the number of data points\n",
    "        len(model['hola']) # the number of components of the word embedding\n",
    "    )\n",
    ")\n",
    "\n",
    "# matrix filling \n",
    "for i,description in enumerate(data['Respuesta']):\n",
    "    vector = to_vector(description,model)\n",
    "    descriptions_matrix[i,] = vector\n",
    "\n",
    "# Concatenate the matrix with the data of each observation\n",
    "data_matrix = np.concatenate([descriptions_matrix,data], axis=1)\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# This is the important matrix\n",
    "# Remove of the 'Nan' data\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:300]).any(axis=1)]\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "# reduce the matrix to the importan\n",
    "data_matrix_without_nan = np.concatenate(\n",
    "    (data_matrix_without_nan[:,:300],                       # Vector of the description\n",
    "    np.reshape(data_matrix_without_nan[:,300], (-1, 1)),    # Cue/Concept\n",
    "    np.reshape(data_matrix_without_nan[:,302], (-1, 1)),    # Codification\n",
    "    np.reshape(data_matrix_without_nan[:,301], (-1, 1))     # Description of the cue\n",
    "    ),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing random generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of test-train data\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000846629762292413\n",
      "0.00047635098789735567\n"
     ]
    }
   ],
   "source": [
    "rand_acc = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    \n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    train_codes=np.unique(train[:,301])\n",
    "\n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    for i in range(len_test):\n",
    "        counter += test[i,301] == np.random.choice(train_codes)\n",
    "    rand_acc.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_acc))\n",
    "print(np.std(rand_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020514490394008466\n",
      "0.00044409578954691806\n"
     ]
    }
   ],
   "source": [
    "rand_acc_top3 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    \n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    train_codes=np.unique(train[:,301])\n",
    "\n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    for i in range(len_test):\n",
    "        for _ in range(3):\n",
    "            val = test[i,301] == np.random.choice(train_codes)\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_acc_top3.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_acc_top3))\n",
    "print(np.std(rand_acc_top3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027678280690328883\n",
      "0.0005545225127296126\n"
     ]
    }
   ],
   "source": [
    "rand_acc_top5 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    \n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    train_codes=np.unique(train[:,301])\n",
    "\n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    for i in range(len_test):\n",
    "        for _ in range(5):\n",
    "            val = test[i,301] == np.random.choice(train_codes)\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_acc_top5.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_acc_top5))\n",
    "print(np.std(rand_acc_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0056007815043959625\n",
      "0.001116667417745506\n"
     ]
    }
   ],
   "source": [
    "rand_acc_top10 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    \n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    train_codes=np.unique(train[:,301])\n",
    "\n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    for i in range(len_test):\n",
    "        for _ in range(10):\n",
    "            val = test[i,301] == np.random.choice(train_codes)\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_acc_top10.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_acc_top10))\n",
    "print(np.std(rand_acc_top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030608922175187236\n",
      "0.0017199755970360474\n"
     ]
    }
   ],
   "source": [
    "rand_acc_top50 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    \n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    train_codes=np.unique(train[:,301])\n",
    "\n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    for i in range(len_test):\n",
    "        for _ in range(50):\n",
    "            val = test[i,301] == np.random.choice(train_codes)\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_acc_top50.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_acc_top50))\n",
    "print(np.std(rand_acc_top50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013741452295669162\n",
      "0.0005310812904689056\n"
     ]
    }
   ],
   "source": [
    "rand_concept_acc = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "\n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    concept_cluster = {\n",
    "                i:np.unique(train[:,301][train[:,300]==i]) for i in np.unique(train[:,300])\n",
    "                }\n",
    "    \n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len_test):\n",
    "        counter += test[i,301] == np.random.choice(concept_cluster[test[i,300]])\n",
    "    rand_concept_acc.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_concept_acc))\n",
    "print(np.std(rand_concept_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041322044936502766\n",
      "0.0019791040571830345\n"
     ]
    }
   ],
   "source": [
    "rand_concept_acc_top3 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "\n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    concept_cluster = {\n",
    "                i:np.unique(train[:,301][train[:,300]==i]) for i in np.unique(train[:,300])\n",
    "                }\n",
    "    \n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len_test):\n",
    "        for _ in range(3):\n",
    "            val = test[i,301] == np.random.choice(concept_cluster[test[i,300]])\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_concept_acc_top3.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_concept_acc_top3))\n",
    "print(np.std(rand_concept_acc_top3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03995441224356887\n",
      "0.0029569354828385525\n"
     ]
    }
   ],
   "source": [
    "rand_concept_acc_top5 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "\n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    concept_cluster = {\n",
    "                i:np.unique(train[:,301][train[:,300]==i]) for i in np.unique(train[:,300])\n",
    "                }\n",
    "    \n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len_test):\n",
    "        for _ in range(3):\n",
    "            val = test[i,301] == np.random.choice(concept_cluster[test[i,300]])\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_concept_acc_top5.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_concept_acc_top5))\n",
    "print(np.std(rand_concept_acc_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04291761641159232\n",
      "0.00209669293806646\n"
     ]
    }
   ],
   "source": [
    "rand_concept_acc_top10 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "\n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    concept_cluster = {\n",
    "                i:np.unique(train[:,301][train[:,300]==i]) for i in np.unique(train[:,300])\n",
    "                }\n",
    "    \n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len_test):\n",
    "        for _ in range(3):\n",
    "            val = test[i,301] == np.random.choice(concept_cluster[test[i,300]])\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_concept_acc_top10.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_concept_acc_top10))\n",
    "print(np.std(rand_concept_acc_top10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041028980788016936\n",
      "0.0017322612931644926\n"
     ]
    }
   ],
   "source": [
    "rand_concept_acc_top50 = []\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "\n",
    "    train = data_matrix_without_nan[train_index,:]\n",
    "    test = data_matrix_without_nan[test_index,:]\n",
    "\n",
    "    concept_cluster = {\n",
    "                i:np.unique(train[:,301][train[:,300]==i]) for i in np.unique(train[:,300])\n",
    "                }\n",
    "    \n",
    "    len_test = len(test)\n",
    "    counter = 0\n",
    "    \n",
    "    for i in range(len_test):\n",
    "        for _ in range(3):\n",
    "            val = test[i,301] == np.random.choice(concept_cluster[test[i,300]])\n",
    "            if val:\n",
    "                counter += val\n",
    "                break\n",
    "    rand_concept_acc_top50.append(counter/len_test)\n",
    "\n",
    "print(np.mean(rand_concept_acc_top50))\n",
    "print(np.std(rand_concept_acc_top50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class creation\n",
    "class PLT_processor:\n",
    "\n",
    "    def __init__(self, method = 0, n_clusters = 500):\n",
    "        \"\"\"\n",
    "        Recives the type of method to use, \n",
    "        - 0: Clasify using K-Means (Simple)\n",
    "        - 1: Clasify to the codification with the same concept \n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.method = method # Method of Processing the data\n",
    "        self.KMeans_dict = {}\n",
    "        self.KMeans_categories = {}\n",
    "\n",
    "        if method == 1:\n",
    "            self.inverse_concept_cluster = {}\n",
    "            self.concept_cluster = {}\n",
    "\n",
    "        self.topk = np.zeros((test.shape[0],500))\n",
    "\n",
    "    def most_frequent(self, List): \n",
    "        \"\"\"\n",
    "        Recives a list of words, and return the word most frequente of\n",
    "        the list\n",
    "        \"\"\"\n",
    "        # ? Agregar la frase 'PENDIENTE' en caso de que haya multiples codificaciones con la misma frecuencia ?\n",
    "        occurence_count = Counter(List) \n",
    "        return occurence_count.most_common(1)[0][0] \n",
    "\n",
    "\n",
    "    def model_train(self, train):\n",
    "        \"\"\"\n",
    "        Recives the train dataset and the number of clusters to train \n",
    "        the k-means model\n",
    "        \"\"\"\n",
    "        \n",
    "        # If the number of clusters is less than the data points aply K Means\n",
    "        if(len(train)>self.n_clusters):\n",
    "            # creates de k-means object\n",
    "            self.kemean = sklearn.cluster.KMeans(n_clusters=self.n_clusters, random_state=0)\n",
    "            # Train the k-means algorithm\n",
    "            self.kemean.fit(train[:,:300])\n",
    "\n",
    "            # print(self.kemean.n_clusters)\n",
    "            # Dataframe of train dataset\n",
    "            df = pd.DataFrame(\n",
    "                np.concatenate([\n",
    "                    np.reshape(train[:,301], (-1, 1)),          # Human codification\n",
    "                    np.reshape(self.kemean.labels_, (-1, 1)),   # Number of the KMean centroid\n",
    "                    np.reshape(train[:,300], (-1, 1))           # Concept of the codification\n",
    "                    ], axis=1), \n",
    "                columns=['Human', 'KMeans', 'Concept'])\n",
    "        # Else if the number of clusters is equal than the data points set a number to each point\n",
    "        elif(len(train)==self.n_clusters):\n",
    "             # Dataframe of train dataset\n",
    "            df = pd.DataFrame(\n",
    "                np.concatenate([\n",
    "                    np.reshape(train[:,301], (-1, 1)),          # Human codification\n",
    "                    np.reshape(range(self.n_clusters), (-1, 1)),   # Number of the KMean centroid\n",
    "                    np.reshape(train[:,300], (-1, 1))           # Concept of the codification\n",
    "                    ], axis=1), \n",
    "                columns=['Human', 'KMeans', 'Concept'])\n",
    "\n",
    "            self.cluster_centers_2 = train[:,:300].astype(float)\n",
    "\n",
    "        # create a dictionary of all the humans codifications for each Cluster\n",
    "        self.KMeans_dict = df.groupby(by='KMeans')['Human'].apply(list).to_dict()\n",
    "\n",
    "        # Fill a dictionary with the most frecuent value in the centroid\n",
    "        for key, val in self.KMeans_dict.items():\n",
    "            self.KMeans_categories[key] = self.most_frequent(val)\n",
    "        \n",
    "        # Generates the prediction for the train dataset\n",
    "        df['KM_Prediction'] = df['KMeans'].map(self.KMeans_categories)\n",
    "\n",
    "        if self.method == 1:\n",
    "            # dictionary of the codifications that doesn't show in a concept\n",
    "            self.not_concept_cluster = {\n",
    "                i:[False if j in np.unique(df['KMeans'][df['Concept']==i]) else True for j in range(self.n_clusters)] \n",
    "                for i in np.unique(df['Concept'])\n",
    "                }\n",
    "            # dictionary of clusters for each concept\n",
    "            self.concept_cluster = {\n",
    "                i:np.unique(df['KMeans'][df['Concept']==i]) for i in np.unique(df['Concept'])\n",
    "                }\n",
    "        # return self.kemean.inertia_\n",
    "\n",
    "    \n",
    "    def get_distances(self, test):\n",
    "        \"\"\"\n",
    "        recives the test data to calculate the distances of each frase, return \n",
    "        a matrix with the distances sorted\n",
    "        \"\"\"\n",
    "\n",
    "        # Distance matrix of each test point to each cluster center\n",
    "        distance_matrix = np.zeros((test.shape[0],self.n_clusters))\n",
    "\n",
    "        if(len(train)>self.n_clusters):\n",
    "            # for each cluster center\n",
    "            for i in range(distance_matrix.shape[1]):    \n",
    "                # Euclidian distance of each point to the i-est cluster center\n",
    "                distance_matrix[:,i]=np.sqrt(np.sum((test[:,:300].astype(float)-self.kemean.cluster_centers_[i,:])**2,axis=1))\n",
    "        elif(len(train)==self.n_clusters):\n",
    "            for i in range(distance_matrix.shape[1]):    \n",
    "                # Euclidian distance of each point to the i-est cluster center\n",
    "                distance_matrix[:,i]=np.sqrt(np.sum((test[:,:300].astype(float)-self.cluster_centers_2[i,:])**2,axis=1))\n",
    "        \n",
    "\n",
    "        if self.method == 1:\n",
    "            # for each datapoint\n",
    "            for i in range(distance_matrix.shape[0]):\n",
    "                # if the centroid not share the same concept asing NaN value\n",
    "                distance_matrix[i, self.not_concept_cluster[test[i,300]]] = np.nan\n",
    "    \n",
    "\n",
    "        # Sorting distances\n",
    "        self.topk=np.argsort(distance_matrix,axis=1)\n",
    "\n",
    "    \n",
    "    def set_labels(self, test):\n",
    "        \"\"\"\n",
    "        Create a new matrix from the clusters sorted and change the value\n",
    "        from numeric to the string according the codification\n",
    "        \"\"\"\n",
    "\n",
    "        # Change of the numeric value to the codification \n",
    "        self.topKS=pd.DataFrame(self.topk)\n",
    "\n",
    "        # create a temporal array of the kmeans categories\n",
    "        tempData = np.array([value for (_, value) in sorted(self.KMeans_categories.items())])\n",
    "        \n",
    "        # for each cluster center\n",
    "        # print(\"Setting labels\")\n",
    "        # print('len temp',len(self.KMeans_categories))\n",
    "        # print('dim topKS',self.topKS.shape[1])\n",
    "        for j in range(self.topKS.shape[1]):\n",
    "            # set the codification of the numeric value in the topk list\n",
    "            self.topKS.iloc[:,j]=tempData[self.topk[:,j]]\n",
    "        \n",
    "        if self.method == 1:\n",
    "            # for each datapoint\n",
    "            for i in range(self.topKS.shape[0]):\n",
    "                # Remove of the clusters that not share the same concept\n",
    "                self.topKS.iloc[i, np.isin(self.topk[i,:], self.concept_cluster[test[i,300]] ,invert=True)]= np.nan\n",
    "\n",
    "\n",
    "    def get_accuracies(self, test):\n",
    "        \"\"\"\n",
    "        Recives the test matrix and return the accuracies of the \n",
    "        diferents predictions\n",
    "        \"\"\"\n",
    "        #Creating the accuracy table to check each data point\n",
    "        testLabel=np.zeros(self.topKS.shape)\n",
    "        indexes_method0=pd.DataFrame(np.zeros((self.topKS.shape[0],2)), columns=['index', 'value']) \n",
    "\n",
    "        #For each data point\n",
    "        for i in range(testLabel.shape[0]):\n",
    "            #Checking if some of the cluster is able to classify it right\n",
    "            boolClass=self.topKS.iloc[i,:]==test[i,301]\n",
    "            if sum(boolClass)>0:\n",
    "                getIndex=boolClass.idxmax()\n",
    "                indexes_method0.iloc[i,0] = getIndex\n",
    "                indexes_method0.iloc[i,1] = self.topKS.iloc[i,getIndex]\n",
    "                #Setting the rest of the data point as 1\n",
    "                testLabel[i,getIndex:]=1\n",
    "            else:\n",
    "                indexes_method0.iloc[i,0] = np.nan\n",
    "                indexes_method0.iloc[i,1] = np.nan\n",
    "        accuracies=testLabel.sum(axis=0)/testLabel.shape[0]\n",
    "\n",
    "        return accuracies\n",
    "\n",
    "    def process(self, train, test):\n",
    "        self.model_train(train)\n",
    "        self.get_distances(test)\n",
    "        self.set_labels(test)\n",
    "        return self.get_accuracies(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3640182351025724\n",
      "0.00933669286880043\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "\n",
    "method0_acc = np.zeros(5)\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    method0_acc[i] = acc[0]\n",
    "    i+=1\n",
    "\n",
    "print(method0_acc.mean())\n",
    "print(method0_acc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41432758059264085\n",
      "0.006234202016922397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "\n",
    "method0_acc_top3 = np.zeros(5)\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    method0_acc_top3[i] = acc[2]\n",
    "    i+=1\n",
    "\n",
    "print(method0_acc_top3.mean())\n",
    "print(method0_acc_top3.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41432758059264085\n",
      "0.006234202016922397\n"
     ]
    }
   ],
   "source": [
    "print(method0_acc_top3.mean())\n",
    "print(method0_acc_top3.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k500_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k500_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36401824 0.41432758 0.43523282 0.46193422 0.52725497]\n",
      "[0.00933669 0.0062342  0.00717074 0.00677852 0.00843342]\n"
     ]
    }
   ],
   "source": [
    "print(k500_acc_top.mean(axis=0))\n",
    "print(k500_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 1000\n",
    "# Top 1, 3, 5, 10, 50\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k1000_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, n_clusters=1000)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k1000_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46610225 0.52132856 0.54343862 0.57284272 0.64649951]\n",
      "[0.00715816 0.00526972 0.00460437 0.00617198 0.00664183]\n"
     ]
    }
   ],
   "source": [
    "print(k1000_acc_top.mean(axis=0))\n",
    "print(k1000_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 3827\n",
    "# Top 1, 3, 5, 10, 50\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k3950_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, n_clusters=len(train_index))\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k3950_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k3950_acc_top.mean(axis=0))\n",
    "print(k3950_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "\n",
    "method1_acc = np.zeros(5)\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(1)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    method1_acc[i] = acc[0]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(method1_acc.mean())\n",
    "print(method1_acc.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busqueda del K optimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35525887 0.35851514 0.3738196  0.36567893 0.37023771]\n",
      "K = 500\n",
      "[0.45522631 0.45685444 0.47362423 0.46532074 0.48111364]\n",
      "K = 1000\n",
      "[0.50765223 0.50553566 0.52523608 0.52588733 0.53451644]\n",
      "K = 1500\n",
      "[0.55600782 0.54802996 0.5643113  0.56268317 0.57701075]\n",
      "K = 2000\n",
      "[0.57749919 0.56789319 0.58661674 0.58645392 0.60094432]\n",
      "K = 2500\n",
      "[0.5983393  0.58661674 0.60957343 0.60126994 0.61657441]\n",
      "K = 3000\n",
      "[0.60892218 0.59899056 0.62552914 0.61217844 0.63008792]\n",
      "K = 3500\n",
      "[0.62243569 0.61055031 0.63122761 0.62536633 0.64327581]\n",
      "K = 4000\n",
      "[0.62845979 0.61624878 0.63822859 0.63399544 0.64734614]\n",
      "K = 4500\n",
      "[0.63676327 0.62080755 0.64864865 0.63936828 0.65646369]\n",
      "K = 5000\n",
      "[0.64034516 0.62650602 0.65369586 0.64832302 0.66232498]\n",
      "K = 5500\n",
      "[0.64799739 0.63464669 0.6602084  0.65581244 0.67323347]\n",
      "K = 6000\n",
      "[0.65239336 0.6370889  0.66151091 0.66216216 0.67909476]\n",
      "K = 6500\n",
      "[0.65760339 0.64229893 0.66655812 0.66688375 0.68251384]\n",
      "K = 7000\n",
      "[0.65841745 0.65076522 0.67046565 0.66818626 0.68430479]\n",
      "K = 7500\n",
      "[0.66590687 0.65141648 0.67290785 0.66965158 0.68642136]\n",
      "K = 8000\n",
      "[0.67127971 0.65630088 0.67795506 0.6760013  0.68870075]\n",
      "K = 8500\n",
      "[0.67453598 0.65581244 0.68121133 0.67502442 0.69114295]\n",
      "K = 9000\n",
      "[0.67746662 0.66118528 0.68463041 0.67876913 0.69195702]\n",
      "K = 9500\n",
      "[0.68186259 0.66216216 0.68593292 0.68349072 0.69667861]\n",
      "K = 10000\n",
      "[0.68414197 0.66541843 0.68886356 0.68707261 0.69830674]\n",
      "K = 10500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a6e97d18ae88>:42: ConvergenceWarning: Number of distinct clusters (10871) found smaller than n_clusters (11000). Possibly due to duplicate points in X.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10934 is out of bounds for axis 0 with size 10871",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0a7bb5572e99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mproc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPLT_processor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a6e97d18ae88>\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, train, test)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_accuracies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-a6e97d18ae88>\u001b[0m in \u001b[0;36mset_labels\u001b[1;34m(self, test)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopKS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[1;31m# set the codification of the numeric value in the topk list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopKS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtempData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 10934 is out of bounds for axis 0 with size 10871"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "rango = range(500,11000+1,500)\n",
    "k_acc_1 = np.zeros((len(rango), 2))\n",
    "j = 0\n",
    "for k in rango:\n",
    "    kfold=KFold(n_splits=5)\n",
    "\n",
    "    temp = np.zeros(5)\n",
    "    i=0\n",
    "    for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "        train = data_matrix_without_nan[train_index, :]\n",
    "        test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "        proc = PLT_processor(0, k)\n",
    "        acc = proc.process(train, test)\n",
    "        \n",
    "        temp[i] = acc[0]\n",
    "        i+=1\n",
    "    print(temp)\n",
    "    k_acc_1[j,0] = temp.mean()\n",
    "    k_acc_1[j,1] = temp.std()\n",
    "    j+=1\n",
    "    print(\"K =\", k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (118454002619)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from turtle import width\n",
    "from plotnine import *\n",
    "\n",
    "(ggplot()+aes(x=rango[:-1], y=k_acc_1[:-1,0])+geom_line()+xlab(\"Numero de clusters\")+ylab(\"Accuracy\")+geom_errorbar(ymax=k_acc_1[:-1,0]+k_acc_1[:-1,1], ymin=k_acc_1[:-1,0]-k_acc_1[:-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(k_acc_1, columns=[\"mean\",\"std\"]).to_csv(r\"../../data/nueva_data/k_acc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "rango = range(25,1301,25)\n",
    "k_acc = np.zeros(len(rango))\n",
    "j = 0\n",
    "for k in rango:\n",
    "    kfold=KFold(n_splits=5)\n",
    "\n",
    "    temp = np.zeros(5)\n",
    "    i=0\n",
    "    for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "        train = data_matrix_without_nan[train_index, :]\n",
    "        test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "        proc = PLT_processor(0, k)\n",
    "        acc = proc.process(train, test)\n",
    "\n",
    "        temp[i] = acc[0]\n",
    "        i+=1\n",
    "    k_acc[j] = temp.mean()\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot()+aes(x=rango, y=k_acc)+geom_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'../../data/nueva_data/propiedades_codigo.csv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEMATIZACION\n",
    "pd.options.mode.chained_assignment = None # Para evitar que se muestre warnings\n",
    "\n",
    "# Normalizacion de los conceptos, descripciones y codificaciones\n",
    "for i in range(len(data)):\n",
    "    data['Respuesta'][i] = lematize(clean_text(data['Respuesta'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dra98\\AppData\\Local\\Temp\\ipykernel_12832\\2310962255.py:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return vec / np.linalg.norm(vec) # divides the vector by their normal\n"
     ]
    }
   ],
   "source": [
    "# Creation of the matrix to make the clustering process\n",
    "descriptions_matrix_lema = np.zeros( # creatign an empty matrix\n",
    "    (\n",
    "        len(data), # the number of data points\n",
    "        len(model['hola']) # the number of components of the word embedding\n",
    "    )\n",
    ")\n",
    "\n",
    "# matrix filling \n",
    "for i,description in enumerate(data['Respuesta']):\n",
    "    vector = to_vector(description,model)\n",
    "    descriptions_matrix_lema[i,] = vector\n",
    "\n",
    "# Concatenate the matrix with the data of each observation\n",
    "data_matrix_lema = np.concatenate([descriptions_matrix_lema,data], axis=1)\n",
    "\n",
    "#--------------------------------------------------------------------------------------\n",
    "# This is the important matrix\n",
    "# Remove of the 'Nan' data\n",
    "data_matrix_without_nan_lema = data_matrix_lema[~pd.isnull(data_matrix_lema[:,:300]).any(axis=1)]\n",
    "#--------------------------------------------------------------------------------------\n",
    "\n",
    "# reduce the matrix to the importan\n",
    "data_matrix_without_nan_lema = np.concatenate(\n",
    "    (data_matrix_without_nan_lema[:,:300],                       # Vector of the description\n",
    "    np.reshape(data_matrix_without_nan_lema[:,300], (-1, 1)),    # Cue/Concept\n",
    "    np.reshape(data_matrix_without_nan_lema[:,302], (-1, 1)),    # Codification\n",
    "    np.reshape(data_matrix_without_nan_lema[:,301], (-1, 1))     # Description of the cue\n",
    "    ),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36922817 0.41354501 0.43043405 0.45640939 0.52116197]\n",
      "[0.01145839 0.01107725 0.01111222 0.00949254 0.01011054]\n"
     ]
    }
   ],
   "source": [
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k500_acc_top_lema = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan_lema):\n",
    "    train = data_matrix_without_nan_lema[train_index, :]\n",
    "    test = data_matrix_without_nan_lema[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k500_acc_top_lema[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "\n",
    "print(k500_acc_top_lema.mean(axis=0))\n",
    "print(k500_acc_top_lema.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47748691 0.5289647  0.54818443 0.57449755 0.64678264]\n",
      "[0.00874872 0.00689851 0.00621774 0.00452374 0.00631262]\n"
     ]
    }
   ],
   "source": [
    "# K = 1000\n",
    "# Top 1, 3, 5, 10, 50\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k1000_acc_top_lema = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan_lema):\n",
    "    train = data_matrix_without_nan_lema[train_index, :]\n",
    "    test = data_matrix_without_nan_lema[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, n_clusters=1000)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k1000_acc_top_lema[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "\n",
    "print(k1000_acc_top_lema.mean(axis=0))\n",
    "print(k1000_acc_top_lema.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = N\n",
    "# Top 1, 3, 5, 10, 50\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "kn_acc_top_lema = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan_lema):\n",
    "    train = data_matrix_without_nan_lema[train_index, :]\n",
    "    test = data_matrix_without_nan_lema[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, n_clusters=len(train))\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        kn_acc_top_lema[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "\n",
    "print(kn_acc_top_lema.mean(axis=0))\n",
    "print(kn_acc_top_lema.std(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f86d5b59def65e88dbeda6389e0ae43ef80c1809fa447fa67ec7c4f0e393c674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
