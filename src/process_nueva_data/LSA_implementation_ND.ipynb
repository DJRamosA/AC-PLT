{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim\n",
    "from collections import Counter \n",
    "import sklearn.cluster\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "data = pd.read_csv(r'../../data/nueva_data/propiedades_codigo.csv', delimiter=\"\\t\")\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format( \n",
    "    r'../../data/SBW-vectors-300-min5.bin.gz', # using the spanish billion words embeddings\n",
    "    binary=True # the model is in binary format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Recive a string and return the string in tokens without punctuations\n",
    "    and in lowercase\n",
    "    \"\"\"\n",
    "    # for each token in the sentence add to the list if is not a punctuation\n",
    "    return [t for t in nlp(text.lower()) if not t.is_punct]\n",
    "    \n",
    "def normalize(tokens):\n",
    "    \"\"\"\n",
    "    Recive al list of string and return in one string without stop words\n",
    "    \"\"\"\n",
    "    # for each token if is not a stop word add the word to the list\n",
    "    words = [t.orth_ for t in tokens if not t.is_stop]\n",
    "\n",
    "    # return the tokens in one string\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizacion de los conceptos, descripciones y codificaciones\n",
    "for i in range(len(data)):\n",
    "    data['Respuesta'][i] = normalize(clean_text(data['Respuesta'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                tierra\n",
       "1                rugoso\n",
       "2          construcción\n",
       "3    desagradable tacto\n",
       "4                 raspa\n",
       "Name: Respuesta, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Respuesta'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: LSA \n",
    "# ? La impletemtación es a todo el dataset o solo a las palabras del train dataset\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "contador = CountVectorizer()\n",
    "tf = contador.fit_transform(data['Respuesta'])\n",
    "transf = TfidfTransformer()\n",
    "tfidf = transf.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x9978 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf[0]\n",
    "# contador.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 1780 # es el numero de codificaciones existentes\n",
    "# numDim = 33 # numero de conceptos\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Plotting the Cumulative Summation of the Explained Variance\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(lsa.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Variance (%)') #for each component\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31864, 1780)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# el vector de los terminos es el resultado del fit_transform\n",
    "tfidf_lsa_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,data[[\"Concepto\", \"Codigo\", \"Respuesta\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class creation\n",
    "class PLT_processor:\n",
    "\n",
    "    def __init__(self, method = 0, n_clusters = 500, vect_size = 300):\n",
    "        \"\"\"\n",
    "        Recives the type of method to use, \n",
    "        - 0: Clasify using K-Means (Simple)\n",
    "        - 1: Clasify to the codification with the same concept \n",
    "        \"\"\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.method = method # Method of Processing the data\n",
    "        self.vect_size = vect_size\n",
    "        self.KMeans_dict = {}\n",
    "        self.KMeans_categories = {}\n",
    "\n",
    "        if method == 1:\n",
    "            self.inverse_concept_cluster = {}\n",
    "            self.concept_cluster = {}\n",
    "\n",
    "\n",
    "    def most_frequent(self, List): \n",
    "        \"\"\"\n",
    "        Recives a list of words, and return the word most frequente of\n",
    "        the list\n",
    "        \"\"\"\n",
    "        # ? Agregar la frase 'PENDIENTE' en caso de que haya multiples codificaciones con la misma frecuencia ?\n",
    "        occurence_count = Counter(List) \n",
    "        return occurence_count.most_common(1)[0][0] \n",
    "\n",
    "\n",
    "    def model_train(self, train):\n",
    "        \"\"\"\n",
    "        Recives the train dataset and the number of clusters to train \n",
    "        the k-means model\n",
    "        \"\"\"\n",
    "        \n",
    "        # If the number of clusters is less than the data points aply K Means\n",
    "        if(len(train)>self.n_clusters):\n",
    "            # creates de k-means object\n",
    "            self.kemean = sklearn.cluster.KMeans(n_clusters=self.n_clusters, random_state=0)\n",
    "            # Train the k-means algorithm\n",
    "            self.kemean.fit(train[:,:self.vect_size])\n",
    "\n",
    "            # print(self.kemean.n_clusters)\n",
    "            # Dataframe of train dataset\n",
    "            df = pd.DataFrame(\n",
    "                np.concatenate([\n",
    "                    np.reshape(train[:,self.vect_size+1], (-1, 1)),          # Human codification\n",
    "                    np.reshape(self.kemean.labels_, (-1, 1)),   # Number of the KMean centroid\n",
    "                    np.reshape(train[:,self.vect_size], (-1, 1))           # Concept of the codification\n",
    "                    ], axis=1), \n",
    "                columns=['Human', 'KMeans', 'Concept'])\n",
    "        # Else if the number of clusters is equal than the data points set a number to each point\n",
    "        elif(len(train)==self.n_clusters):\n",
    "             # Dataframe of train dataset\n",
    "            df = pd.DataFrame(\n",
    "                np.concatenate([\n",
    "                    np.reshape(train[:,self.vect_size+1], (-1, 1)),          # Human codification\n",
    "                    np.reshape(range(self.n_clusters), (-1, 1)),   # Number of the KMean centroid\n",
    "                    np.reshape(train[:,self.vect_size], (-1, 1))           # Concept of the codification\n",
    "                    ], axis=1), \n",
    "                columns=['Human', 'KMeans', 'Concept'])\n",
    "\n",
    "            self.cluster_centers_2 = train[:,:self.vect_size].astype(float)\n",
    "\n",
    "        # create a dictionary of all the humans codifications for each Cluster\n",
    "        self.KMeans_dict = df.groupby(by='KMeans')['Human'].apply(list).to_dict()\n",
    "\n",
    "        # Fill a dictionary with the most frecuent value in the centroid\n",
    "        for key, val in self.KMeans_dict.items():\n",
    "            self.KMeans_categories[key] = self.most_frequent(val)\n",
    "        \n",
    "        # Generates the prediction for the train dataset\n",
    "        df['KM_Prediction'] = df['KMeans'].map(self.KMeans_categories)\n",
    "\n",
    "        if self.method == 1:\n",
    "            # dictionary of the codifications that doesn't show in a concept\n",
    "            self.not_concept_cluster = {\n",
    "                i:[False if j in np.unique(df['KMeans'][df['Concept']==i]) else True for j in range(self.n_clusters)] \n",
    "                for i in np.unique(df['Concept'])\n",
    "                }\n",
    "            # dictionary of clusters for each concept\n",
    "            self.concept_cluster = {\n",
    "                i:np.unique(df['KMeans'][df['Concept']==i]) for i in np.unique(df['Concept'])\n",
    "                }\n",
    "        # return self.kemean.inertia_\n",
    "\n",
    "    \n",
    "    def get_distances(self, test):\n",
    "        \"\"\"\n",
    "        recives the test data to calculate the distances of each frase, return \n",
    "        a matrix with the distances sorted\n",
    "        \"\"\"\n",
    "\n",
    "        # Distance matrix of each test point to each cluster center\n",
    "        distance_matrix = np.zeros((test.shape[0],self.n_clusters))\n",
    "\n",
    "        if(len(train)>self.n_clusters):\n",
    "            # for each cluster center\n",
    "            for i in range(distance_matrix.shape[1]):    \n",
    "                # Euclidian distance of each point to the i-est cluster center\n",
    "                distance_matrix[:,i]=np.sqrt(np.sum((test[:,:self.vect_size].astype(float)-self.kemean.cluster_centers_[i,:])**2,axis=1))\n",
    "        elif(len(train)==self.n_clusters):\n",
    "            for i in range(distance_matrix.shape[1]):    \n",
    "                # Euclidian distance of each point to the i-est cluster center\n",
    "                distance_matrix[:,i]=np.sqrt(np.sum((test[:,:self.vect_size].astype(float)-self.cluster_centers_2[i,:])**2,axis=1))\n",
    "        \n",
    "\n",
    "        if self.method == 1:\n",
    "            # for each datapoint\n",
    "            for i in range(distance_matrix.shape[0]):\n",
    "                # if the centroid not share the same concept asing NaN value\n",
    "                distance_matrix[i, self.not_concept_cluster[test[i,self.vect_size]]] = np.nan\n",
    "    \n",
    "\n",
    "        # Sorting distances\n",
    "        self.topk=np.argsort(distance_matrix,axis=1)\n",
    "\n",
    "    \n",
    "    def set_labels(self, test):\n",
    "        \"\"\"\n",
    "        Create a new matrix from the clusters sorted and change the value\n",
    "        from numeric to the string according the codification\n",
    "        \"\"\"\n",
    "\n",
    "        # Change of the numeric value to the codification \n",
    "        self.topKS=pd.DataFrame(self.topk)\n",
    "\n",
    "        # create a temporal array of the kmeans categories\n",
    "        tempData = np.array([value for (_, value) in sorted(self.KMeans_categories.items())])\n",
    "        \n",
    "        # for each cluster center\n",
    "        # print(\"Setting labels\")\n",
    "        # print('len temp',len(self.KMeans_categories))\n",
    "        # print('dim topKS',self.topKS.shape[1])\n",
    "        for j in range(self.topKS.shape[1]):\n",
    "            # set the codification of the numeric value in the topk list\n",
    "            self.topKS.iloc[:,j]=tempData[self.topk[:,j]]\n",
    "        \n",
    "        if self.method == 1:\n",
    "            # for each datapoint\n",
    "            for i in range(self.topKS.shape[0]):\n",
    "                # Remove of the clusters that not share the same concept\n",
    "                self.topKS.iloc[i, np.isin(self.topk[i,:], self.concept_cluster[test[i,self.vect_size]] ,invert=True)]= np.nan\n",
    "\n",
    "\n",
    "    def get_accuracies(self, test):\n",
    "        \"\"\"\n",
    "        Recives the test matrix and return the accuracies of the \n",
    "        diferents predictions\n",
    "        \"\"\"\n",
    "        #Creating the accuracy table to check each data point\n",
    "        testLabel=np.zeros(self.topKS.shape)\n",
    "        indexes_method0=pd.DataFrame(np.zeros((self.topKS.shape[0],2)), columns=['index', 'value']) \n",
    "\n",
    "        #For each data point\n",
    "        for i in range(testLabel.shape[0]):\n",
    "            #Checking if some of the cluster is able to classify it right\n",
    "            boolClass=self.topKS.iloc[i,:]==test[i,numDim+1]\n",
    "            if sum(boolClass)>0:\n",
    "                getIndex=boolClass.idxmax()\n",
    "                indexes_method0.iloc[i,0] = getIndex\n",
    "                indexes_method0.iloc[i,1] = self.topKS.iloc[i,getIndex]\n",
    "                #Setting the rest of the data point as 1\n",
    "                testLabel[i,getIndex:]=1\n",
    "            else:\n",
    "                indexes_method0.iloc[i,0] = np.nan\n",
    "                indexes_method0.iloc[i,1] = np.nan\n",
    "        accuracies=testLabel.sum(axis=0)/testLabel.shape[0]\n",
    "\n",
    "        return accuracies\n",
    "\n",
    "    def process(self, train, test):\n",
    "        self.model_train(train)\n",
    "        self.get_distances(test)\n",
    "        self.set_labels(test)\n",
    "        return self.get_accuracies(test)\n",
    "\n",
    "    def train_process(self, train):\n",
    "        self.model_train(train)\n",
    "        self.get_distances(train)\n",
    "        self.set_labels(train)\n",
    "        return self.get_accuracies(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31150362 0.32124031 0.32455908 0.3285997  0.35858651]\n",
      "[0.00337765 0.00309452 0.00173608 0.00223465 0.0031068 ]\n"
     ]
    }
   ],
   "source": [
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k500_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.train_process(train)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k500_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "\n",
    "print(k500_acc_top.mean(axis=0))\n",
    "print(k500_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28643662 0.29625964 0.29911557 0.30338366 0.33454733]\n",
      "[0.01022057 0.00995744 0.0104379  0.00977119 0.00952298]\n"
     ]
    }
   ],
   "source": [
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "k500_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        k500_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "\n",
    "print(k500_acc_top.mean(axis=0))\n",
    "print(k500_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25513121 0.26790425 0.27076798 0.27580502 0.31913761]\n",
      "[0.00229781 0.002606   0.00254393 0.00279371 0.00194133]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 300 # igual al word2vec\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)\n",
    "\n",
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,data[[\"Concepto\", \"Codigo\", \"Respuesta\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n",
    "\n",
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "lsa300_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.train_process(train)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        lsa300_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "print(lsa300_acc_top.mean(axis=0))\n",
    "print(lsa300_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24491645 0.26013739 0.26311881 0.26804603 0.3129555 ]\n",
      "[0.01096282 0.01008161 0.00995862 0.0104182  0.00827782]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 300 # igual al word2vec\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)\n",
    "\n",
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,data[[\"Concepto\", \"Codigo\", \"Respuesta\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n",
    "\n",
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "lsa300_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        lsa300_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "print(lsa300_acc_top.mean(axis=0))\n",
    "print(lsa300_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17675122 0.18742941 0.19230953 0.19836652 0.24595158]\n",
      "[0.00250656 0.0021721  0.00293323 0.00323856 0.00323893]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 120 # numero de conceptos\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)\n",
    "\n",
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,data[[\"Concepto\", \"Codigo\", \"Respuesta\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n",
    "\n",
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "lsa120_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.train_process(train)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        lsa120_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "print(lsa120_acc_top.mean(axis=0))\n",
    "print(lsa120_acc_top.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16262919 0.17502566 0.18108264 0.18773588 0.23575226]\n",
      "[0.01220591 0.01283126 0.01244811 0.01082548 0.00796148]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import seaborn as sns\n",
    "\n",
    "# Igualando los numeros de dimensiones con el Word2Vec\n",
    "numDim = 120 # numero de conceptos\n",
    "vocab = contador.get_feature_names_out()\n",
    "\n",
    "lsa = TruncatedSVD(n_components=numDim, n_iter=100, random_state=42)\n",
    "# U, Sigma, VT = np.linalg.svd(tfidf.toarray())\n",
    "tfidf_lsa_data = lsa.fit_transform(tfidf)\n",
    "\n",
    "# sns.barplot(x=list(range(len(Sigma))), y = Sigma)\n",
    "\n",
    "tfidf_lsa_data\n",
    "data_matrix = np.concatenate([tfidf_lsa_data,data[[\"Concepto\", \"Codigo\", \"Respuesta\"]]], axis=1)\n",
    "\n",
    "data_matrix_without_nan = data_matrix[~pd.isnull(data_matrix[:,:numDim]).any(axis=1)]\n",
    "\n",
    "# K = 500\n",
    "# Top 1, 3, 5, 10, 50\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "lsa120_acc_top = np.zeros((5, 5))\n",
    "\n",
    "tops=(0,2,4,9,49)\n",
    "\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kfold.split(data_matrix_without_nan):\n",
    "    train = data_matrix_without_nan[train_index, :]\n",
    "    test = data_matrix_without_nan[test_index, :]\n",
    "\n",
    "    proc = PLT_processor(0, vect_size=numDim)\n",
    "    acc = proc.process(train, test)\n",
    "\n",
    "    for j in range(len(tops)):\n",
    "        lsa120_acc_top[i,j] = acc[tops[j]]\n",
    "\n",
    "    i+=1\n",
    "print(lsa120_acc_top.mean(axis=0))\n",
    "print(lsa120_acc_top.std(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f86d5b59def65e88dbeda6389e0ae43ef80c1809fa447fa67ec7c4f0e393c674"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
